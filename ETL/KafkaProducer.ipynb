{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "245c28ed-996a-4b52-939d-784ea40a10c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Producer for the HealthCosts dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "379521e8-3e63-40ec-bbf7-c7e73c4b2661",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create Kafka error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bac85f99-548e-417d-a4df-d5b34f3f12f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def error_cb(err):\n",
    "    \"\"\" The error callback is used for generic client errors. These\n",
    "        errors are generally to be considered informational as the client will\n",
    "        automatically try to recover from all errors, and no extra action\n",
    "        is typically required by the application.\n",
    "        For this example however, we terminate the application if the client\n",
    "        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n",
    "        authentication errors (_AUTHENTICATION). \"\"\"\n",
    "\n",
    "    print(\"Client error: {}\".format(err))\n",
    "    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n",
    "       err.code() == KafkaError._AUTHENTICATION:\n",
    "        # Any exception raised from this callback will be re-raised from the\n",
    "        # triggering flush() or poll() call.\n",
    "        raise KafkaException(err)\n",
    "\n",
    "\n",
    "def acked(err, msg):\n",
    "    \"\"\" \n",
    "        Error callback is used for generic issues for producer errors. \n",
    "        \n",
    "        Parameters:\n",
    "            err (err): Error flag.\n",
    "            msg (str): Error message that was part of the callback.\n",
    "    \"\"\"\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: %s: %s\" % (str(msg), str(err)))\n",
    "    else:\n",
    "        print(\"Message produced: %s\" % (str(msg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e4415e3a-17a2-45d5-8b75-ec92cb8cd9fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Set up strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2add4eb1-7801-4235-9581-006f35c2d2af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from time import sleep\n",
    "import uuid\n",
    "from confluent_kafka import Producer, Consumer, KafkaError, KafkaException\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "import json\n",
    "\n",
    "#KAFKA variables, get from your cluster and put into a config file\n",
    "from config import confluentClusterName\n",
    "from config import confluentBootstrapServers\n",
    "from config import confluentTopicName\n",
    "from config import schemaRegistryUrl\n",
    "from config import confluentApiKey\n",
    "from config import confluentSecret\n",
    "from config import confluentRegistryApiKey\n",
    "from config import confluentRegistrySecret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "92f3ca33-c41e-4dc1-8214-3d703e7ad654",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "create topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a1290a32-2a01-4c90-9a68-81e83e8c035c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create topic\n",
    "\n",
    "# Create admin_client\n",
    "admin_client = AdminClient({\n",
    "    'bootstrap.servers': confluentBootstrapServers,\n",
    "    'sasl.mechanism': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': confluentApiKey,\n",
    "    'sasl.password': confluentSecret,\n",
    "    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'error_cb': error_cb,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a71a5667-4a61-4460-9292-6ff4586fab57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #If needed, we can delete a topic to \"reset\" it\n",
    "\n",
    "# try:\n",
    "#     topics =['insurance-capstone2']\n",
    "#     fs = admin_client.delete_topics(topics, request_timeout=30)\n",
    "\n",
    "#     for topic, f in fs.items():\n",
    "#         try:\n",
    "#             f.result()  # The result itself is None\n",
    "#             print(\"Topic {} deleted\".format(topic))\n",
    "#         except Exception as e:\n",
    "#             print(\"Failed to delete topic {}: {}\".format(topic, e))\n",
    "# except Exception as e:\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9529b0b3-2f8f-40c5-a2ef-0e9ca06adbed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Add a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5b81a672-4650-43d9-9f29-879babfa1031",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Add topic\n",
    "# topic_list = []\n",
    "# topic_list.append(NewTopic(confluentTopicName, 1, 3))\n",
    "# admin_client.create_topics(topic_list)\n",
    "# futures = admin_client.create_topics(topic_list)\n",
    "# try:\n",
    "#     record_metadata = []\n",
    "#     for k, future in futures.items():\n",
    "#         # f = i.get(timeout=10)\n",
    "#         print(f\"type(k): {type(k)}\")\n",
    "#         print(f\"type(v): {type(future)}\")\n",
    "#         print(future.result())\n",
    "# except KafkaError:\n",
    "#     # Decide what to do if produce request failed...\n",
    "#     print(traceback.format_exc())\n",
    "#     result = 'Fail'\n",
    "# finally:\n",
    "#     print(\"finally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4a11ed93-b157-4184-bed3-970cf33017c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creat producer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e1424b2-2ad8-4932-bf07-8fbabab7944c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create producer object\n",
    "\n",
    "p = Producer({\n",
    "    'bootstrap.servers': confluentBootstrapServers,\n",
    "    'sasl.mechanism': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': confluentApiKey,\n",
    "    'sasl.password': confluentSecret,\n",
    "    'group.id': str(1),  # this will create a new consumer group on each invocation.\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'error_cb': error_cb,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da4d4341-0380-4e4c-9c98-0837bb8b94a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "define mount point to read in data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "37292f37-47f6-4c3b-ae8c-cf3c5fd323b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mount the capstone container\n",
    "from config import storageAccount\n",
    "from config import storageContainer\n",
    "from config import clientSecret\n",
    "from config import clientid\n",
    "from config import mount_point\n",
    "    \n",
    "    \n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "   \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "   \"fs.azure.account.oauth2.client.id\": clientid,\n",
    "   \"fs.azure.account.oauth2.client.secret\": clientSecret,\n",
    "   \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n",
    "   \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "try:\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = f\"abfss://{storageContainer}@{storageAccount}.dfs.core.windows.net/\", \n",
    "mount_point = mount_point, \n",
    "extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "312c3bbc-f264-447a-b133-1bb7a7202179",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs\n",
    "ls /mnt/capstone-group2-data/datain/rawdata/HealthCosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ddf1a32e-91ac-43a2-98c3-e5012378d603",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "\n",
    "#dictionary to read healthcosts\n",
    "combinedDict = {}\n",
    "\n",
    "#read in csv files\n",
    "df = spark.read.csv('/mnt/capstone-group2-data/datain/rawdata/HealthCosts/insurance.csv', header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ff8f42c6-a636-4339-9a12-84d469ac0b4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create N instances of HealthCosts data and push\n",
    "data_entries = df.count()\n",
    "for i in range(data_entries):\n",
    "    #If you want to randomize the data feed from the file, you can uncomment the line below\n",
    "    #rand_row = random.randint(0, data_entries - 1)\n",
    "    \n",
    "    for data_col in df.columns:\n",
    "        combinedDict[data_col] = df.collect()[i][data_col]\n",
    "        \n",
    "    p.produce(confluentTopicName, json.dumps(combinedDict))\n",
    "    p.flush()\n",
    "    sleep(5)\n",
    "    print(f'# {i}', combinedDict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "804f7a86-48dc-4caa-854f-4e2e9cba3d6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "KafkaProducer",
   "notebookOrigID": 2451669969096139,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
