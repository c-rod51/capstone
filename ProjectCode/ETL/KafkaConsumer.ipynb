{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c3e5313f-6002-4207-af81-4201daeabe7f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Kafka Consumer for the Insurance Dataset(s)\n",
    "\n",
    "Create error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "876758d7-a18e-4656-81b2-24d4e83f882a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions\n",
    "from pyspark.sql.functions import concat, col, lit\n",
    "from pyspark.sql.types import StringType, DecimalType, IntegerType, ByteType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25af01b1-872f-4953-b955-7813d8722746",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def error_cb(err):\n",
    "    \"\"\" The error callback is used for generic client errors. These\n",
    "        errors are generally to be considered informational as the client will\n",
    "        automatically try to recover from all errors, and no extra action\n",
    "        is typically required by the application.\n",
    "        For this example however, we terminate the application if the client\n",
    "        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n",
    "        authentication errors (_AUTHENTICATION). \"\"\"\n",
    "\n",
    "    print(\"Client error: {}\".format(err))\n",
    "    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n",
    "       err.code() == KafkaError._AUTHENTICATION:\n",
    "        # Any exception raised from this callback will be re-raised from the\n",
    "        # triggering flush() or poll() call.\n",
    "        raise KafkaException(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7f98c72-7f19-46c5-a062-30a521ad43bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Set up the consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b3b04a38-2803-4ce9-ae03-5acbca87fe4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from time import sleep\n",
    "import uuid\n",
    "from confluent_kafka import Producer, Consumer, KafkaError, KafkaException\n",
    "import json\n",
    "\n",
    "\n",
    "#KAFKA variables, get from your cluster and put into a config file\n",
    "from config import confluentClusterName\n",
    "from config import confluentBootstrapServers\n",
    "from config import confluentTopicName\n",
    "from config import schemaRegistryUrl\n",
    "from config import confluentApiKey\n",
    "from config import confluentSecret\n",
    "from config import confluentRegistryApiKey\n",
    "from config import confluentRegistrySecret\n",
    "\n",
    "\n",
    "#Kakfa Class Setup.\n",
    "c = Consumer({\n",
    "    'bootstrap.servers': confluentBootstrapServers,\n",
    "    'sasl.mechanism': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': confluentApiKey,\n",
    "    'sasl.password': confluentSecret,# this will create a new consumer group on each invocation.\n",
    "    'group.id': str(1),\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'enable.auto.commit': True,\n",
    "    'error_cb': error_cb,\n",
    "})\n",
    "\n",
    "c.subscribe(['insurance-capstone2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2f17aa77-14dc-43f2-974b-7dcfff838688",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Read the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c16b8d47-fa6c-4516-ad2e-99e8c0ac72f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aString = {}\n",
    "\n",
    "kafkaListDictionaries = []\n",
    "\n",
    "while(True):\n",
    "    try:\n",
    "        msg = c.poll(timeout=15)\n",
    "        print(msg)\n",
    "        if msg is None:\n",
    "            break\n",
    "        elif msg.error():\n",
    "            print(\"Consumer error: {}\".format(msg.error()))\n",
    "            break\n",
    "        else:\n",
    "            aString=json.loads('{}'.format(msg.value().decode('utf-8')))\n",
    "            aString['timestamp'] = msg.timestamp()[1]\n",
    "            kafkaListDictionaries.append(aString)\n",
    "            charge = aString['charges']\n",
    "            print(\"New claim with charge of: \" + charge)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cc9a8848-ec40-461d-bca7-401a13c104bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Start (ET)L for the InusranceCharges Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0f6e8d81-d67f-4d95-9ef8-63fbe0deffde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# turn kafkaListDictionaries into spark dataframe\n",
    "sparkdf = spark.createDataFrame(kafkaListDictionaries)\n",
    "display(sparkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9d197e48-6996-4569-bd00-5580cbc9228b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Change Smoker Y/N to 1/0\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "sparkdf = sparkdf.withColumn('smoker', regexp_replace('smoker', 'no', '0'))\n",
    "sparkdf = sparkdf.withColumn('smoker', regexp_replace('smoker', 'yes', '1'))\n",
    "display(sparkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6cc6d405-fe4a-4d4b-86bf-5a017ec5f25e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sparkdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9d86d74c-0d39-4fb4-92e5-1e01a66e93d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Convert the data types appropriately for database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8de66911-1a6b-4b26-a184-3b8a214f61b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = sparkdf.withColumn(\"age\", col(\"age\").cast(IntegerType()))\n",
    "df = df.withColumn(\"bmi\", col(\"bmi\").cast(DecimalType()))\n",
    "df = df.withColumn(\"charges\", col(\"charges\").cast(DecimalType()))\n",
    "df = df.withColumn(\"children\", col(\"children\").cast(IntegerType()))\n",
    "df = df.withColumn(\"smoker\", col(\"smoker\").cast(ByteType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "62a64ef5-cbcd-410e-aaed-0d4ae99e8c8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "84d45bbe-f393-487a-a402-f29739fa8a48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a696e6de-5146-49b8-95f9-45561a7c38b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Drop null values\n",
    "df = sparkdf.dropna()\n",
    "\n",
    "#Drop duplicates\n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "571cb938-68e8-4cc2-8840-f8471ec2732a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's set the ranges for data values to filter incoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1c8b35b0-c119-4fec-b97d-f40e18336349",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "age_lower = 18\n",
    "age_upper = 120\n",
    "children_lower = 0\n",
    "children_upper = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "864acf31-f94a-4509-8ae4-b4819721f5a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.where(df.age >= age_lower)\n",
    "df = df.where(df.age <= age_upper)\n",
    "df = df.where(df.children >= children_lower)\n",
    "df = df.where(df.children <= children_upper)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2e002f2e-8828-4711-b8c8-86999ac90a59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "11f6ebab-dd2a-4d1a-9f6c-1f616d54be35",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Save the data to CSV file; then load to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3dee2acb-a4ca-41ab-9550-d1d760da9895",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mount the capstone container (output)\n",
    "from config import storageAccount\n",
    "from config import storageContainer\n",
    "from config import clientSecret\n",
    "from config import clientid\n",
    "mount_point = \"/mnt/capstone-group2-data/dataout\"\n",
    "    \n",
    "    \n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "   \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "   \"fs.azure.account.oauth2.client.id\": clientid,\n",
    "   \"fs.azure.account.oauth2.client.secret\": clientSecret,\n",
    "   \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n",
    "   \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "try:\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = f\"abfss://{storageContainer}@{storageAccount}.dfs.core.windows.net/\", \n",
    "mount_point = mount_point, \n",
    "extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b3ac1343-d31f-4b50-80e2-0e3d20e81380",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/mnt/capstone-group2-data/dataout/cleandata/cleanHealthCosts/clean_insurance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4b711d52-9c44-45da-89dd-40d4e76a5cf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "KafkaConsumer",
   "notebookOrigID": 2451669969096296,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
